## 가장 단순한 머신러닝 선형 회귀
일차함수(퍼셉트론)을 찾는 함수

### 평균 제곱 오차
오차 산출

### 경사 하강법
최적화, 가중치 조정

= MSE 최소화

```python
# x 값이 총 몇 개인지 셉니다.
n=len(x)

# 경사 하강법을 시작합니다.
for i in range(epochs):                  # 에포크 수 만큼 반복
    
    y_pred = a * x + b                   # 예측 값을 구하는 식입니다. 
    error = y - y_pred                   # 실제 값과 비교한 오차를 error로 놓습니다.

    # error는 오차의 배열

    a_diff = (2/n) * sum(-x * (error))   # 오차 함수를 a로 편미분한 값입니다. 
    b_diff = (2/n) * sum(-(error))       # 오차 함수를 b로 편미분한 값입니다. 
    
    a = a - lr * a_diff     # 학습률을 곱해 기존의 a 값을 업데이트합니다.
    b = b - lr * b_diff     # 학습률을 곱해 기존의 b 값을 업데이트합니다.
    
    if i % 100 == 0:        # 100번 반복될 때마다 현재의 a 값, b 값을 출력합니다.
        print("epoch=%.f, 기울기=%.04f, 절편=%.04f" % (i, a, b))        
```

단순선형회귀에서는 가중치를 a라고 쓰고 다중선형회귀에서는 w로 씀
마찬가지로 편향을 b(그냥 b) -> b(bias)라고 씀
